"""
Tests de validaci√≥n para NLPAnalyzer (Orquestador).

Estos tests verifican la integraci√≥n de los 3 analizadores:
- CoherenceAnalyzer: Coherencia sem√°ntica
- AmbiguityDetector: Detecci√≥n de ambig√ºedades
- ClarityAnalyzer: An√°lisis de claridad

Tambi√©n verifica:
- C√°lculo de score global ponderado
- Evaluaci√≥n de cumplimiento WCAG (ACC-07, ACC-08, ACC-09)
- Combinaci√≥n de recomendaciones
"""

from app.nlp.analyzer import NLPAnalyzer


def test_initialization_default_weights():
    """Test 1: Inicializaci√≥n con pesos por defecto."""
    print("=" * 70)
    print("TEST 1: Inicializaci√≥n con Pesos por Defecto")
    print("=" * 70)

    analyzer = NLPAnalyzer()

    print(f"\n‚úì Pesos configurados:")
    print(f"  Coherencia: {analyzer.coherence_weight}")
    print(f"  Ambig√ºedad: {analyzer.ambiguity_weight}")
    print(f"  Claridad: {analyzer.clarity_weight}")
    print(f"  Total: {analyzer.coherence_weight + analyzer.ambiguity_weight + analyzer.clarity_weight}")

    assert analyzer.coherence_weight == 0.40
    assert analyzer.ambiguity_weight == 0.40
    assert analyzer.clarity_weight == 0.20
    assert abs((analyzer.coherence_weight + analyzer.ambiguity_weight + analyzer.clarity_weight) - 1.0) < 0.01

    print("\n‚úÖ Test 1 PASADO\n")


def test_initialization_custom_weights():
    """Test 2: Inicializaci√≥n con pesos personalizados."""
    print("=" * 70)
    print("TEST 2: Inicializaci√≥n con Pesos Personalizados")
    print("=" * 70)

    analyzer = NLPAnalyzer(
        coherence_weight=0.50,
        ambiguity_weight=0.30,
        clarity_weight=0.20
    )

    print(f"\n‚úì Pesos personalizados:")
    print(f"  Coherencia: {analyzer.coherence_weight}")
    print(f"  Ambig√ºedad: {analyzer.ambiguity_weight}")
    print(f"  Claridad: {analyzer.clarity_weight}")

    assert analyzer.coherence_weight == 0.50
    assert analyzer.ambiguity_weight == 0.30
    assert analyzer.clarity_weight == 0.20

    print("\n‚úÖ Test 2 PASADO\n")


def test_initialization_invalid_weights():
    """Test 3: Rechaza pesos inv√°lidos (no suman 1.0)."""
    print("=" * 70)
    print("TEST 3: Validaci√≥n de Pesos Inv√°lidos")
    print("=" * 70)

    try:
        analyzer = NLPAnalyzer(
            coherence_weight=0.50,
            ambiguity_weight=0.40,
            clarity_weight=0.30  # Total = 1.20 (inv√°lido)
        )
        assert False, "Deber√≠a lanzar ValueError para pesos inv√°lidos"
    except ValueError as e:
        print(f"\n‚úì Pesos inv√°lidos rechazados: {str(e)}")

    print("\n‚úÖ Test 3 PASADO\n")


def test_analyze_complete_website():
    """Test 4: An√°lisis completo de un sitio web."""
    print("=" * 70)
    print("TEST 4: An√°lisis Completo de Sitio Web")
    print("=" * 70)

    analyzer = NLPAnalyzer()

    text_corpus = {
        'url': 'https://educacion.gob.bo',
        'sections': [
            {
                'heading': 'Misi√≥n Institucional',
                'heading_level': 2,
                'content': 'El Ministerio de Educaci√≥n garantiza educaci√≥n de calidad. Promovemos la formaci√≥n integral de estudiantes y maestros.',
                'word_count': 18
            },
            {
                'heading': 'Servicios Educativos',
                'heading_level': 2,
                'content': 'Ofrecemos programas de formaci√≥n docente, registro de estudiantes y certificaci√≥n acad√©mica oficial.',
                'word_count': 14
            },
            {
                'heading': 'Ver m√°s',  # Problem√°tico (gen√©rico)
                'heading_level': 3,
                'content': 'El PIB creci√≥ 4.5% en el trimestre fiscal.',  # Incoherente con heading
                'word_count': 8
            }
        ],
        'links': [
            {'text': 'Descargar formulario de inscripci√≥n 2024', 'url': '/formularios/inscripcion'},
            {'text': 'Ver m√°s', 'url': '/noticias'},  # Problem√°tico
            {'text': 'Leer m√°s', 'url': '/info'},  # Problem√°tico
            {'text': 'Consultar requisitos para titulaci√≥n', 'url': '/titulacion'}
        ],
        'labels': [
            {'text': 'Nombre completo del estudiante', 'for': 'nombre'},
            {'text': 'Fecha de nacimiento', 'for': 'fecha'},
            {'text': 'N√∫mero', 'for': 'numero'}  # Problem√°tico (ambiguo)
        ]
    }

    result = analyzer.analyze_website(text_corpus)

    print(f"\nüìä RESULTADOS DEL AN√ÅLISIS:")
    print(f"  Score Global: {result['global_score']}/100")
    print(f"  Score Coherencia: {result['coherence_score']}/100")
    print(f"  Score Ambig√ºedad: {result['ambiguity_score']}/100")
    print(f"  Score Claridad: {result['clarity_score']}/100")

    print(f"\n‚úì Cumplimiento WCAG:")
    for criterion, passed in result['wcag_compliance'].items():
        status = "‚úì" if passed else "‚úó"
        print(f"  {status} {criterion}: {'CUMPLE' if passed else 'NO CUMPLE'}")

    print(f"\n‚úì Estad√≠sticas:")
    print(f"  Secciones analizadas: {result['total_sections_analyzed']}")
    print(f"  Textos analizados: {result['total_texts_analyzed']}")
    print(f"  Recomendaciones: {len(result['recommendations'])}")

    print(f"\n‚ö†Ô∏è Primeras 5 recomendaciones:")
    for i, rec in enumerate(result['recommendations'][:5], 1):
        print(f"  {i}. {rec[:100]}...")

    # Validaciones
    assert 0 <= result['global_score'] <= 100
    assert 0 <= result['coherence_score'] <= 100
    assert 0 <= result['ambiguity_score'] <= 100
    assert 0 <= result['clarity_score'] <= 100

    assert 'ACC-07' in result['wcag_compliance']
    assert 'ACC-08' in result['wcag_compliance']
    assert 'ACC-09' in result['wcag_compliance']

    assert result['total_sections_analyzed'] == 3
    assert result['total_texts_analyzed'] > 0  # links + labels + headings
    assert len(result['recommendations']) > 0

    assert 'coherence' in result['details']
    assert 'ambiguity' in result['details']
    assert 'clarity' in result['details']

    print("\n‚úÖ Test 4 PASADO\n")


def test_weighted_score_calculation():
    """Test 5: Verifica c√°lculo de score global ponderado."""
    print("=" * 70)
    print("TEST 5: C√°lculo de Score Global Ponderado")
    print("=" * 70)

    analyzer = NLPAnalyzer(
        coherence_weight=0.50,
        ambiguity_weight=0.30,
        clarity_weight=0.20
    )

    # Calcular manualmente
    coherence_score = 80.0
    ambiguity_score = 60.0
    clarity_score = 70.0

    expected_global = (80.0 * 0.50) + (60.0 * 0.30) + (70.0 * 0.20)
    expected_global = round(expected_global, 2)

    # Usar m√©todo privado directamente
    calculated_global = analyzer._calculate_global_score(
        coherence_score,
        ambiguity_score,
        clarity_score
    )

    print(f"\n‚úì C√°lculo de score global:")
    print(f"  Coherencia: {coherence_score} √ó {analyzer.coherence_weight} = {coherence_score * analyzer.coherence_weight}")
    print(f"  Ambig√ºedad: {ambiguity_score} √ó {analyzer.ambiguity_weight} = {ambiguity_score * analyzer.ambiguity_weight}")
    print(f"  Claridad: {clarity_score} √ó {analyzer.clarity_weight} = {clarity_score * analyzer.clarity_weight}")
    print(f"  Global: {calculated_global}/100 (esperado: {expected_global}/100)")

    assert calculated_global == expected_global, \
        f"Score global {calculated_global} no coincide con esperado {expected_global}"

    print("\n‚úÖ Test 5 PASADO\n")


def test_wcag_compliance_all_pass():
    """Test 6: WCAG cumple cuando no hay problemas."""
    print("=" * 70)
    print("TEST 6: WCAG Compliance - Todos Cumplen")
    print("=" * 70)

    analyzer = NLPAnalyzer()

    # Corpus perfecto (sin problemas)
    text_corpus = {
        'url': 'https://test.gob.bo',
        'sections': [
            {
                'heading': 'Servicios de Salud P√∫blica',
                'heading_level': 2,
                'content': 'Ofrecemos atenci√≥n m√©dica de calidad. Nuestros servicios incluyen consultas y emergencias.',
                'word_count': 12
            }
        ],
        'links': [
            {'text': 'Descargar informe anual 2024', 'url': '/informe'},
            {'text': 'Ver requisitos para atenci√≥n m√©dica', 'url': '/requisitos'}
        ],
        'labels': [
            {'text': 'Nombre completo del paciente', 'for': 'nombre'},
            {'text': 'Fecha de nacimiento', 'for': 'fecha'}
        ]
    }

    result = analyzer.analyze_website(text_corpus)

    print(f"\n‚úì Cumplimiento WCAG:")
    for criterion, passed in result['wcag_compliance'].items():
        status = "‚úì" if passed else "‚úó"
        print(f"  {status} {criterion}: {'CUMPLE' if passed else 'NO CUMPLE'}")

    # Deber√≠a cumplir todos (no hay problemas)
    assert result['wcag_compliance']['ACC-07'], "ACC-07 deber√≠a cumplir (no hay textos ambiguos)"
    assert result['wcag_compliance']['ACC-08'], "ACC-08 deber√≠a cumplir (no hay textos gen√©ricos)"
    assert result['wcag_compliance']['ACC-09'], "ACC-09 deber√≠a cumplir (no hay textos no descriptivos)"

    print("\n‚úÖ Test 6 PASADO\n")


def test_wcag_compliance_failures():
    """Test 7: WCAG no cumple cuando hay problemas."""
    print("=" * 70)
    print("TEST 7: WCAG Compliance - Fallos Detectados")
    print("=" * 70)

    analyzer = NLPAnalyzer()

    # Corpus con problemas espec√≠ficos
    text_corpus = {
        'url': 'https://test.gob.bo',
        'sections': [
            {
                'heading': 'Informaci√≥n',  # ACC-09: No descriptivo
                'heading_level': 2,
                'content': 'Contenido de ejemplo.',
                'word_count': 3
            }
        ],
        'links': [
            {'text': 'Ver m√°s', 'url': '/mas'},  # ACC-08: Gen√©rico
            {'text': 'Ok', 'url': '/ok'}  # ACC-08: Muy corto
        ],
        'labels': [
            {'text': 'Nombre', 'for': 'nombre'},  # ACC-07: Ambiguo
            {'text': 'Fecha', 'for': 'fecha'}  # ACC-07: Ambiguo
        ]
    }

    result = analyzer.analyze_website(text_corpus)

    print(f"\n‚úì Cumplimiento WCAG:")
    for criterion, passed in result['wcag_compliance'].items():
        status = "‚úì" if passed else "‚úó"
        print(f"  {status} {criterion}: {'CUMPLE' if passed else 'NO CUMPLE'}")

    # Deber√≠a fallar todos
    assert not result['wcag_compliance']['ACC-07'], "ACC-07 NO deber√≠a cumplir (hay textos ambiguos)"
    assert not result['wcag_compliance']['ACC-08'], "ACC-08 NO deber√≠a cumplir (hay textos gen√©ricos/cortos)"
    assert not result['wcag_compliance']['ACC-09'], "ACC-09 NO deber√≠a cumplir (hay textos no descriptivos)"

    print("\n‚úÖ Test 7 PASADO\n")


def test_recommendations_prioritization():
    """Test 8: Verifica priorizaci√≥n de recomendaciones."""
    print("=" * 70)
    print("TEST 8: Priorizaci√≥n de Recomendaciones")
    print("=" * 70)

    analyzer = NLPAnalyzer(max_recommendations=10)

    # Corpus con problemas variados para generar muchas recomendaciones
    text_corpus = {
        'url': 'https://test.gob.bo',
        'sections': [
            {
                'heading': 'Programas de Vacunaci√≥n',
                'heading_level': 2,
                'content': 'El PIB de Bolivia creci√≥ significativamente en el √∫ltimo trimestre fiscal. Las exportaciones aumentaron.',  # Incoherente
                'word_count': 14
            },
            {
                'heading': 'Informaci√≥n',  # No descriptivo
                'heading_level': 2,
                'content': 'El presente Decreto Supremo establece las disposiciones reglamentarias correspondientes a la implementaci√≥n del Sistema Nacional de Inversi√≥n P√∫blica y Financiamiento para el Desarrollo Integral con mecanismos de articulaci√≥n interinstitucional.',  # Oraci√≥n muy larga
                'word_count': 28
            }
        ],
        'links': [
            {'text': 'Ver m√°s', 'url': '/1'},  # Gen√©rico
            {'text': 'Leer m√°s', 'url': '/2'},  # Gen√©rico
            {'text': 'Click aqu√≠', 'url': '/3'}  # Gen√©rico
        ],
        'labels': [
            {'text': 'Nombre', 'for': 'nombre'},  # Ambiguo
            {'text': 'Fecha', 'for': 'fecha'}  # Ambiguo
        ]
    }

    result = analyzer.analyze_website(text_corpus)

    print(f"\n‚úì Total de recomendaciones: {len(result['recommendations'])} (m√°x: {analyzer.max_recommendations})")
    print(f"\n‚úì Primeras 10 recomendaciones (priorizadas):")
    for i, rec in enumerate(result['recommendations'][:10], 1):
        # Identificar categor√≠a
        if '[Ambig√ºedad' in rec:
            category = "Ambig√ºedad (Prioridad 1)"
        elif '[Coherencia' in rec:
            category = "Coherencia (Prioridad 2)"
        elif '[Claridad' in rec:
            category = "Claridad (Prioridad 3)"
        else:
            category = "Otra"

        print(f"  {i}. [{category}] {rec[:80]}...")

    # Verificar que hay recomendaciones
    assert len(result['recommendations']) > 0
    assert len(result['recommendations']) <= analyzer.max_recommendations

    # Las primeras deber√≠an ser de ambig√ºedad (WCAG cr√≠tico)
    first_recs = result['recommendations'][:3]
    ambiguity_count = sum(1 for rec in first_recs if '[Ambig√ºedad' in rec)
    print(f"\n‚úì Primeras 3 recomendaciones: {ambiguity_count} son de Ambig√ºedad (WCAG)")

    print("\n‚úÖ Test 8 PASADO\n")


def test_empty_corpus():
    """Test 9: Manejo de corpus vac√≠o."""
    print("=" * 70)
    print("TEST 9: Corpus Vac√≠o")
    print("=" * 70)

    analyzer = NLPAnalyzer()

    text_corpus = {
        'url': 'https://test.gob.bo',
        'sections': [],
        'links': [],
        'labels': []
    }

    result = analyzer.analyze_website(text_corpus)

    print(f"\n‚úì Resultados con corpus vac√≠o:")
    print(f"  Score Global: {result['global_score']}/100")
    print(f"  Secciones analizadas: {result['total_sections_analyzed']}")
    print(f"  Textos analizados: {result['total_texts_analyzed']}")

    assert result['global_score'] >= 0.0
    assert result['total_sections_analyzed'] == 0
    assert result['total_texts_analyzed'] == 0

    print("\n‚úÖ Test 9 PASADO\n")


def test_partial_corpus():
    """Test 10: Corpus parcial (solo algunas secciones)."""
    print("=" * 70)
    print("TEST 10: Corpus Parcial")
    print("=" * 70)

    analyzer = NLPAnalyzer()

    # Solo secciones, sin links ni labels
    text_corpus = {
        'url': 'https://test.gob.bo',
        'sections': [
            {
                'heading': 'Servicios de Atenci√≥n',
                'heading_level': 2,
                'content': 'Ofrecemos servicios de atenci√≥n al ciudadano.',
                'word_count': 7
            }
        ]
        # No links, no labels
    }

    result = analyzer.analyze_website(text_corpus)

    print(f"\n‚úì Corpus parcial (solo secciones):")
    print(f"  Score Global: {result['global_score']}/100")
    print(f"  Coherencia: {result['coherence_score']}/100")
    print(f"  Ambig√ºedad: {result['ambiguity_score']}/100")
    print(f"  Claridad: {result['clarity_score']}/100")

    assert result['total_sections_analyzed'] == 1
    # Solo analizar√° el heading de la secci√≥n
    assert result['total_texts_analyzed'] >= 1

    print("\n‚úÖ Test 10 PASADO\n")


def test_integration_all_analyzers():
    """Test 11: Verifica que los 3 analizadores se ejecutan."""
    print("=" * 70)
    print("TEST 11: Integraci√≥n de Todos los Analizadores")
    print("=" * 70)

    analyzer = NLPAnalyzer()

    text_corpus = {
        'url': 'https://test.gob.bo',
        'sections': [
            {
                'heading': 'Educaci√≥n Superior',
                'heading_level': 2,
                'content': 'Promovemos la educaci√≥n universitaria y formaci√≥n profesional de calidad.',
                'word_count': 10
            }
        ],
        'links': [
            {'text': 'Consultar programas acad√©micos disponibles', 'url': '/programas'}
        ],
        'labels': [
            {'text': 'C√≥digo de estudiante', 'for': 'codigo'}
        ]
    }

    result = analyzer.analyze_website(text_corpus)

    print(f"\n‚úì Verificando ejecuci√≥n de analizadores:")

    # Coherencia
    coherence_details = result['details']['coherence']
    print(f"  ‚úì CoherenceAnalyzer ejecutado: {coherence_details['sections_analyzed']} secciones")
    assert coherence_details['sections_analyzed'] > 0

    # Ambig√ºedad
    ambiguity_details = result['details']['ambiguity']
    print(f"  ‚úì AmbiguityDetector ejecutado: {ambiguity_details['total_analyzed']} textos")
    assert ambiguity_details['total_analyzed'] > 0

    # Claridad
    clarity_details = result['details']['clarity']
    print(f"  ‚úì ClarityAnalyzer ejecutado: {clarity_details['total_analyzed']} textos")
    assert clarity_details['total_analyzed'] > 0

    print(f"\n‚úì Scores generados:")
    print(f"  Coherencia: {result['coherence_score']}/100")
    print(f"  Ambig√ºedad: {result['ambiguity_score']}/100")
    print(f"  Claridad: {result['clarity_score']}/100")
    print(f"  Global: {result['global_score']}/100")

    print("\n‚úÖ Test 11 PASADO\n")


def run_all_tests():
    """Ejecuta todos los tests en orden."""
    print("\n" + "=" * 70)
    print("INICIANDO TESTS DE NLPAnalyzer (Orquestador)")
    print("=" * 70)
    print("Integraci√≥n de CoherenceAnalyzer + AmbiguityDetector + ClarityAnalyzer")
    print("=" * 70 + "\n")

    try:
        test_initialization_default_weights()
        test_initialization_custom_weights()
        test_initialization_invalid_weights()
        test_analyze_complete_website()
        test_weighted_score_calculation()
        test_wcag_compliance_all_pass()
        test_wcag_compliance_failures()
        test_recommendations_prioritization()
        test_empty_corpus()
        test_partial_corpus()
        test_integration_all_analyzers()

        print("\n" + "=" * 70)
        print("‚úÖ TODOS LOS TESTS PASARON EXITOSAMENTE")
        print("=" * 70)

        print("\nüìä Resumen:")
        print("  ‚úì Inicializaci√≥n y validaci√≥n de pesos: OK")
        print("  ‚úì An√°lisis completo de sitios web: OK")
        print("  ‚úì C√°lculo de score global ponderado: OK")
        print("  ‚úì Evaluaci√≥n WCAG (ACC-07, ACC-08, ACC-09): OK")
        print("  ‚úì Priorizaci√≥n de recomendaciones: OK")
        print("  ‚úì Manejo de casos especiales (vac√≠o, parcial): OK")
        print("  ‚úì Integraci√≥n de 3 analizadores: OK")

        return True

    except Exception as e:
        print("\n" + "=" * 70)
        print("‚ùå TESTS FALLARON")
        print("=" * 70)
        print(f"Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = run_all_tests()
    exit(0 if success else 1)
